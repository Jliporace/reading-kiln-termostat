{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bdba6c9a-926d-4450-a092-be9d9134f3de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a simple data logging thermometer would give much more reliable results with a fraction of the effort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6df2967",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step #1: Localize the LCD on the thermostat. This can be done using edge detection since there is enough contrast between the plastic shell and the LCD.\n",
    "# Step #2: Extract the LCD. Given an input edge map I can find contours and look for outlines with a rectangular shape — the largest rectangular region should correspond to the LCD. A perspective transform will give me a nice extraction of the LCD.\n",
    "# Step #3: Extract the digit regions. Once I have the LCD itself I can focus on extracting the digits. Since there seems to be contrast between the digit regions and the background of the LCD I’m confident that thresholding and morphological operations can accomplish this.\n",
    "# Step #4: Identify the digits. Recognizing the actual digits with OpenCV will involve dividing the digit ROI into seven segments. From there I can apply pixel counting on the thresholded image to determine if a given segment is “on” or “off”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d43dba58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import imutils\n",
    "import numpy as np\n",
    "from IPython.display import Image, display\n",
    "from imutils import contours\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ba0159c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "DIGITS_LOOKUP = {\n",
    "\t(1, 1, 1, 0, 1, 1, 1): 0,\n",
    "\t(0, 0, 1, 0, 0, 1, 0): 1,\n",
    "\t(1, 0, 1, 1, 1, 1, 0): 2,\n",
    "\t(1, 0, 1, 1, 0, 1, 1): 3,\n",
    "\t(0, 1, 1, 1, 0, 1, 0): 4,\n",
    "\t(1, 1, 0, 1, 0, 1, 1): 5,\n",
    "\t(1, 1, 0, 1, 1, 1, 1): 6,\n",
    "\t(1, 0, 1, 0, 0, 1, 0): 7,\n",
    "\t(1, 1, 1, 1, 1, 1, 1): 8,\n",
    "\t(1, 1, 1, 1, 0, 1, 1): 9\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a9dde8d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_image(image):\n",
    "    cv2.imshow('image',image)\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0543d4df",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"example.png\")\n",
    "\n",
    "image = imutils.resize(image, height=500)\n",
    "# show_image(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "71ccdcb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# show_image(gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bce9dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "blurred = cv2.GaussianBlur(gray, (5,5), 0)\n",
    "# show_image(blurred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4d3f547",
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = cv2.Canny(blurred, 50, 200, 255)\n",
    "# show_image(edged)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "51cb87f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts = cv2.findContours(edged.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "cnts = sorted(cnts, key=cv2.contourArea, reverse=True)\n",
    "displayCnt = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "24270fb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for c in cnts:\n",
    "\t# approximate the contour\n",
    "\tperi = cv2.arcLength(c, True)\n",
    "\tapprox = cv2.approxPolyDP(c, 0.02 * peri, True)\n",
    "\t# if the contour has four vertices, then we have found\n",
    "\t# the thermostat display\n",
    "\tif len(approx) == 4:\n",
    "\t\tdisplayCnt = approx\n",
    "\t\tbreak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74079e84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def order_points(pts):\n",
    "\t# initialzie a list of coordinates that will be ordered\n",
    "\t# such that the first entry in the list is the top-left,\n",
    "\t# the second entry is the top-right, the third is the\n",
    "\t# bottom-right, and the fourth is the bottom-left\n",
    "\trect = np.zeros((4, 2), dtype = \"float32\")\n",
    "\t# the top-left point will have the smallest sum, whereas\n",
    "\t# the bottom-right point will have the largest sum\n",
    "\ts = pts.sum(axis = 1)\n",
    "\trect[0] = pts[np.argmin(s)]\n",
    "\trect[2] = pts[np.argmax(s)]\n",
    "\t# now, compute the difference between the points, the\n",
    "\t# top-right point will have the smallest difference,\n",
    "\t# whereas the bottom-left will have the largest difference\n",
    "\tdiff = np.diff(pts, axis = 1)\n",
    "\trect[1] = pts[np.argmin(diff)]\n",
    "\trect[3] = pts[np.argmax(diff)]\n",
    "\t# return the ordered coordinates\n",
    "\treturn rect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "13a1da2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def four_point_transform(image, pts):\n",
    "\t# obtain a consistent order of the points and unpack them\n",
    "\t# individually\n",
    "\trect = order_points(pts)\n",
    "\t(tl, tr, br, bl) = rect\n",
    "\t# compute the width of the new image, which will be the\n",
    "\t# maximum distance between bottom-right and bottom-left\n",
    "\t# x-coordiates or the top-right and top-left x-coordinates\n",
    "\twidthA = np.sqrt(((br[0] - bl[0]) ** 2) + ((br[1] - bl[1]) ** 2))\n",
    "\twidthB = np.sqrt(((tr[0] - tl[0]) ** 2) + ((tr[1] - tl[1]) ** 2))\n",
    "\tmaxWidth = max(int(widthA), int(widthB))\n",
    "\t# compute the height of the new image, which will be the\n",
    "\t# maximum distance between the top-right and bottom-right\n",
    "\t# y-coordinates or the top-left and bottom-left y-coordinates\n",
    "\theightA = np.sqrt(((tr[0] - br[0]) ** 2) + ((tr[1] - br[1]) ** 2))\n",
    "\theightB = np.sqrt(((tl[0] - bl[0]) ** 2) + ((tl[1] - bl[1]) ** 2))\n",
    "\tmaxHeight = max(int(heightA), int(heightB))\n",
    "\t# now that we have the dimensions of the new image, construct\n",
    "\t# the set of destination points to obtain a \"birds eye view\",\n",
    "\t# (i.e. top-down view) of the image, again specifying points\n",
    "\t# in the top-left, top-right, bottom-right, and bottom-left\n",
    "\t# order\n",
    "\tdst = np.array([\n",
    "\t\t[0, 0],\n",
    "\t\t[maxWidth - 1, 0],\n",
    "\t\t[maxWidth - 1, maxHeight - 1],\n",
    "\t\t[0, maxHeight - 1]], dtype = \"float32\")\n",
    "\t# compute the perspective transform matrix and then apply it\n",
    "\tM = cv2.getPerspectiveTransform(rect, dst)\n",
    "\twarped = cv2.warpPerspective(image, M, (maxWidth, maxHeight))\n",
    "\t# return the warped image\n",
    "\treturn warped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8ba4358d",
   "metadata": {},
   "outputs": [],
   "source": [
    "warped = four_point_transform(gray, displayCnt.reshape(4, 2))\n",
    "output = four_point_transform(image, displayCnt.reshape(4, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2421d0ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: Ignoring XDG_SESSION_TYPE=wayland on Gnome. Use QT_QPA_PLATFORM=wayland to run on Wayland anyway.\n"
     ]
    }
   ],
   "source": [
    "show_image(warped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "eafc0e51",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "238c5b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# threshold the warped image, then apply a series of morphological\n",
    "# operations to cleanup the thresholded image\n",
    "thresh = cv2.threshold(warped, 0, 255,\n",
    "\tcv2.THRESH_BINARY_INV | cv2.THRESH_OTSU)[1]\n",
    "kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (1, 5))\n",
    "thresh = cv2.morphologyEx(thresh, cv2.MORPH_OPEN, kernel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "14b77168",
   "metadata": {},
   "outputs": [],
   "source": [
    "show_image(thresh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6e816284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# find contours in the thresholded image, then initialize the\n",
    "# digit contours lists\n",
    "cnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL,\n",
    "\tcv2.CHAIN_APPROX_SIMPLE)\n",
    "cnts = imutils.grab_contours(cnts)\n",
    "digitCnts = []\n",
    "# loop over the digit area candidates\n",
    "for c in cnts:\n",
    "\t# compute the bounding box of the contour\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\t# if the contour is sufficiently large, it must be a digit\n",
    "\tif w >= 15 and (h >= 30 and h <= 40):\n",
    "\t\tdigitCnts.append(c)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "176497cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(digitCnts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "7b9c2506",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sort the contours from left-to-right, then initialize the\n",
    "# actual digits themselves\n",
    "digitCnts = contours.sort_contours(digitCnts,\n",
    "\tmethod=\"left-to-right\")[0]\n",
    "digits = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "67b906ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over each of the digits\n",
    "for c in digitCnts:\n",
    "\t# extract the digit ROI\n",
    "\t(x, y, w, h) = cv2.boundingRect(c)\n",
    "\troi = thresh[y:y + h, x:x + w]\n",
    "\t# compute the width and height of each of the 7 segments\n",
    "\t# we are going to examine\n",
    "\t(roiH, roiW) = roi.shape\n",
    "\t(dW, dH) = (int(roiW * 0.25), int(roiH * 0.15))\n",
    "\tdHC = int(roiH * 0.05)\n",
    "\t# define the set of 7 segments\n",
    "\tsegments = [\n",
    "\t\t((0, 0), (w, dH)),\t# top\n",
    "\t\t((0, 0), (dW, h // 2)),\t# top-left\n",
    "\t\t((w - dW, 0), (w, h // 2)),\t# top-right\n",
    "\t\t((0, (h // 2) - dHC) , (w, (h // 2) + dHC)), # center\n",
    "\t\t((0, h // 2), (dW, h)),\t# bottom-left\n",
    "\t\t((w - dW, h // 2), (w, h)),\t# bottom-right\n",
    "\t\t((0, h - dH), (w, h))\t# bottom\n",
    "\t]\n",
    "\ton = [0] * len(segments)\n",
    "    \n",
    "    # loop over the segments\n",
    "\tfor (i, ((xA, yA), (xB, yB))) in enumerate(segments):\n",
    "\t\t# extract the segment ROI, count the total number of\n",
    "\t\t# thresholded pixels in the segment, and then compute\n",
    "\t\t# the area of the segment\n",
    "\t\tsegROI = roi[yA:yB, xA:xB]\n",
    "\t\ttotal = cv2.countNonZero(segROI)\n",
    "\t\tarea = (xB - xA) * (yB - yA)\n",
    "\t\t# if the total number of non-zero pixels is greater than\n",
    "\t\t# 50% of the area, mark the segment as \"on\"\n",
    "\t\tif total / float(area) > 0.38:\n",
    "\t\t\ton[i]= 1\n",
    "\t# lookup the digit and draw it on the image\n",
    "\tdigit = DIGITS_LOOKUP[tuple(on)]\n",
    "\tdigits.append(digit)\n",
    "\tcv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 1)\n",
    "\tcv2.putText(output, str(digit), (x - 10, y - 10),\n",
    "\t\tcv2.FONT_HERSHEY_SIMPLEX, 0.65, (0, 255, 0), 2)\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "c1469c19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[3, 4, 5]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "digits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "1d1c8078",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 0, 1, 1, 0, 1, 1)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\t(1, 0, 1, 1, 0, 1, 1): 3,\n",
    "\t(0, 1, 1, 1, 0, 1, 0): 4,\n",
    "\t(1, 1, 0, 1, 0, 1, 1): 5,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "8e265b36",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8.9 °C\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# display the digits\n",
    "print(u\"{}.{} \\u00b0C\".format(*digits))\n",
    "cv2.imshow(\"Input\", image)\n",
    "cv2.imshow(\"Output\", output)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e77b48",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
